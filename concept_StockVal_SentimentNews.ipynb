{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept: Stock buy/sell action through News\n",
    "- https://www.zenrows.com/blog/403-web-scraping#set-fake-user-agent >> Handling errors\n",
    "- https://www.youtube.com/watch?v=o-zM8onpQZY >> Using finviz to get stocks and NTLK processing\n",
    "- https://medium.datadriveninvestor.com/sentiment-analysis-of-stocks-from-financial-news-using-python-82ebdcefb638 >> Using finviz to get stocks and NTLK processing\n",
    "- https://towardsdatascience.com/stock-news-sentiment-analysis-with-python-193d4b4378d4 >> Using finviz to get stocks and NTLK processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be trying to create script that scrapes and creates  recommendation for the top performing stocks from October2023 by checking news related to this stocks and their sentiment analysis result.<br>\n",
    "This script will try to performance from news related to the company (Stock)\n",
    "<br>As our portfolio we will be using the best S&P 500 stocks as of October 2023\n",
    "<br>Company and ticker symbol\tPerformance in 2023\n",
    "- Tesla (TSLA)\t\n",
    "- Royal Caribbean Cruises (RCL)\n",
    "- Carnival Corporation (CCL)\t\n",
    "- General Electric (GE)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\joaqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# First import libraries we use\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we set the website finviz from where we will extract the stock news, finviz is the easiest and most used in examples checked as pre work\n",
    "finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
    "tickers = ['TSLA','RCL','CCL','GE']\n",
    "n=4\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "   'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "   'Accept-Encoding': 'none',\n",
    "   'Accept-Language': 'en-US,en;q=0.8',\n",
    "   'Connection': 'keep-alive'}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will gather news from the stock tickers we defined on our portfolio and iterate the tickers \n",
    "news_tables = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    url = finwiz_url + ticker\n",
    "    req = Request(url=url,headers=hdr) \n",
    "    resp = urlopen(req)    \n",
    "    html = BeautifulSoup(resp, features=\"lxml\")\n",
    "    news_table = html.find(id='news-table')\n",
    "    news_tables[ticker] = news_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recent News Headlines for TSLA: \n",
      "Stock Traders Face Pivotal Week as Apple Steals Fed Spotlight ( Today 12:05PM )\n",
      "Tesla's Competition Are Feeling the Heat ( 10:30AM )\n",
      "Even With Shrinking Profits, Tesla's Business Is Supercharged Compared to the Competition ( 10:00AM )\n",
      "Dan Niles looking to re-short Tesla, Apple: Insider trades & hedge funds weekly ( 09:39AM )\n",
      "\n",
      "\n",
      "Recent News Headlines for RCL: \n",
      "Carnival Cruise Line shares key dining rule some passengers ignore ( Today 09:36AM )\n",
      "Royal Caribbean Cruises Ltd. (NYSE:RCL) Q3 2023 Earnings Call Transcript ( Oct-28-23 03:26PM )\n",
      "Q3 2023 Royal Caribbean Cruises Ltd Earnings Call ( Oct-27-23 02:06AM )\n",
      "Royal Caribbean Cruises (RCL) Q3 2023 Earnings Call Transcript ( Oct-26-23 06:00PM )\n",
      "\n",
      "\n",
      "Recent News Headlines for CCL: \n",
      "2 Reasons You Might Seriously Regret Buying Carnival Cruise Stock ( Today 05:15AM )\n",
      "Fresh Puerto Rican Tostones and Stone Crab Highlight New Caribbean Menu on Holland America Line ( Oct-27-23 02:18PM )\n",
      "SEABOURN UNVEILS NEW EXPEDITION ITINERARIES FOR 2025-2026, EXPLORING ANTARCTICA, THE ARCTIC, AMAZON, KIMBERLEY, SOUTH PACIFIC AND MORE ( Oct-25-23 02:45PM )\n",
      "Carnival Is Negligent Over Covid Outbreak, Court Finds. What It Means for Cruise Operators. ( 11:24AM )\n",
      "\n",
      "\n",
      "Recent News Headlines for GE: \n",
      "Tools & Outdoor Weakness Hurt Stanley Black's (SWK) Sales in Q3 ( Oct-27-23 12:43PM )\n",
      "Stock Market Correction Intensifies; Google, Meta, Microsoft, Amazon Are Big Earnings Movers: Weekly Review ( 12:19PM )\n",
      "Duke Energy to build end-to-end green hydrogen system in Florida ( 11:09AM )\n",
      "Alzheimer's drug Leqembi: The twice-monthly infusion could be available in injection form ( 08:30AM )\n"
     ]
    }
   ],
   "source": [
    "# Get news from tr (table rows) and extract data, print each ticker news to check visually\n",
    "try:\n",
    "    for ticker in tickers:\n",
    "        df = news_tables[ticker]\n",
    "        df_tr = df.findAll('tr')\n",
    "    \n",
    "        print ('\\n')\n",
    "        print ('Recent News Headlines for {}: '.format(ticker))\n",
    "        \n",
    "        for i, table_row in enumerate(df_tr):\n",
    "            a_text = table_row.a.text\n",
    "            td_text = table_row.td.text\n",
    "            td_text = td_text.strip()\n",
    "            print(a_text,'(',td_text,')')\n",
    "            if i == n-1:\n",
    "                break\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate the news to get ticker date time and the text of the news\n",
    "parsed_news = []\n",
    "for file_name, news_table in news_tables.items():\n",
    "    for x in news_table.findAll('tr'):\n",
    "        text = x.a.get_text() \n",
    "        date_scrape = x.td.text.split()\n",
    "\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "            \n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "\n",
    "        ticker = file_name.split('_')[0]\n",
    "        \n",
    "        parsed_news.append([ticker, date, time, text])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
    "news = pd.DataFrame(parsed_news, columns=columns)\n",
    "scores = news['Headline'].apply(analyzer.polarity_scores).tolist()\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "news = news.join(df_scores, rsuffix='_right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for all the news['Date'] that are equal to the string 'Today' and set TODAY() for the rest use the date\n",
    "\n",
    "# Today's date\n",
    "today = datetime.today()\n",
    "\n",
    "# Check for all the news['Date'] that are equal to the string 'Today'\n",
    "if 'Today' in news['Date'].values:\n",
    "    # Add today's date in date type to those rows\n",
    "    news.loc[news['Date'] == 'Today', 'Date'] = today\n",
    "else:\n",
    "    # Convert the rest of the news['Date'] to datetime64 type\n",
    "    news['Date'] = pd.to_datetime(news.Date).dt.date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "              Date     Time    neg    neu    pos  compound\n",
      "Ticker                                                    \n",
      "TSLA    2023-10-29  12:05PM  0.268  0.732  0.000   -0.5106\n",
      "TSLA    2023-10-29  10:30AM  0.000  0.769  0.231    0.1280\n",
      "TSLA    2023-10-29  10:00AM  0.000  0.791  0.209    0.4404\n",
      "TSLA    2023-10-29  09:39AM  0.000  1.000  0.000    0.0000\n",
      "TSLA    2023-10-29  09:05AM  0.000  1.000  0.000    0.0000\n",
      "\n",
      "\n",
      "              Date     Time    neg   neu    pos  compound\n",
      "Ticker                                                   \n",
      "RCL     2023-10-29  09:36AM  0.197  0.63  0.173   -0.0772\n",
      "RCL     2023-10-28  03:26PM  0.000  1.00  0.000    0.0000\n",
      "RCL     2023-10-27  02:06AM  0.000  1.00  0.000    0.0000\n",
      "RCL     2023-10-26  06:00PM  0.000  1.00  0.000    0.0000\n",
      "RCL     2023-10-26  05:52PM  0.000  0.70  0.300    0.4576\n",
      "\n",
      "\n",
      "              Date     Time    neg    neu    pos  compound\n",
      "Ticker                                                    \n",
      "CCL     2023-10-29  05:15AM  0.391  0.609  0.000   -0.5423\n",
      "CCL     2023-10-27  02:18PM  0.000  0.734  0.266    0.5719\n",
      "CCL     2023-10-25  02:45PM  0.000  0.868  0.132    0.3470\n",
      "CCL     2023-10-25  11:24AM  0.000  1.000  0.000    0.0000\n",
      "CCL     2023-10-25  10:03AM  0.000  0.845  0.155    0.2960\n",
      "\n",
      "\n",
      "              Date     Time    neg    neu    pos  compound\n",
      "Ticker                                                    \n",
      "GE      2023-10-27  12:43PM  0.437  0.563  0.000   -0.7351\n",
      "GE      2023-10-27  12:19PM  0.000  0.884  0.116    0.1779\n",
      "GE      2023-10-27  11:09AM  0.000  0.811  0.189    0.2732\n",
      "GE      2023-10-27  08:30AM  0.000  1.000  0.000    0.0000\n",
      "GE      2023-10-27  08:30AM  0.000  1.000  0.000    0.0000\n",
      "\n",
      "\n",
      "        Mean Sentiment\n",
      "Ticker                \n",
      "GE                0.21\n",
      "RCL               0.16\n",
      "CCL               0.16\n",
      "TSLA             -0.03\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the unique tickers\n",
    "unique_ticker = news['Ticker'].unique().tolist()\n",
    "news_dict = {name: news.loc[news['Ticker'] == name] for name in unique_ticker}\n",
    "\n",
    "# Calculate and set the mean sentiment fron the compound values\n",
    "values = []\n",
    "for ticker in tickers: \n",
    "    dataframe = news_dict[ticker]\n",
    "    dataframe = dataframe.set_index('Ticker')\n",
    "    dataframe = dataframe.drop(columns = ['Headline'])\n",
    "    print ('\\n')\n",
    "    print (dataframe.head())\n",
    "    \n",
    "    mean = round(dataframe['compound'].mean(), 2)\n",
    "    values.append(mean)\n",
    "\n",
    "   \n",
    "df = pd.DataFrame(list(zip(tickers, values)), columns =['Ticker', 'Mean Sentiment']) \n",
    "df = df.set_index('Ticker')\n",
    "df = df.sort_values('Mean Sentiment', ascending=False)\n",
    "print ('\\n')\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
